{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T14:30:56.412412Z",
     "start_time": "2025-05-08T14:30:53.246956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow.pytorch\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "from graph_reinforcement_learning_using_blockchain_data import config\n",
    "from graph_reinforcement_learning_using_blockchain_data.modeling import gnn\n",
    "\n",
    "config.load_dotenv()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-05-08 16:30:55.804\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mgraph_reinforcement_learning_using_blockchain_data.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m12\u001B[0m - \u001B[1mPROJ_ROOT path is: /Users/liamtessendorf/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:31:51.243194Z",
     "start_time": "2025-05-08T14:30:56.418022Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = torch.load(config.FLASHBOTS_Q2_DATA_DIR / \"trx_graphs.pt\", weights_only=False)",
   "id": "3db4e207bf425645",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:31:52.700244Z",
     "start_time": "2025-05-08T14:31:51.275299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_list = [d for sublist in dataset for d in sublist]\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    data_list, [0.8, 0.2], generator=generator\n",
    ")"
   ],
   "id": "acea19278dbc8f93",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:31:52.771297Z",
     "start_time": "2025-05-08T14:31:52.730737Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)",
   "id": "fdaa416d2a513002",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:31:52.785148Z",
     "start_time": "2025-05-08T14:31:52.779203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=512, shuffle=True, exclude_keys=[\"account_mapping\"], drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, exclude_keys=[\"account_mapping\"], drop_last=False\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    dataset, batch_size=256, shuffle=False, exclude_keys=[\"account_mapping\"], drop_last=False\n",
    ")"
   ],
   "id": "1decd391a46d9f18",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:38:07.928604Z",
     "start_time": "2025-05-07T13:38:07.220071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for step, data in enumerate(test_loader):\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    print(\"=======\")\n",
    "    print(f\"Number of graphs in the current batch: {data.num_graphs}\")\n",
    "    print(data.edge_index.shape)\n",
    "    print()"
   ],
   "id": "b9fa9c1f817dc329",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 399])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 473])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 528])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 413])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 495])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 488])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 407])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 419])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 462])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 498])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 934])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 486])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 460])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 403])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 474])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 411])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 405])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 424])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 459])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 493])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 501])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 407])\n",
      "\n",
      "Step 25:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 406])\n",
      "\n",
      "Step 26:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 433])\n",
      "\n",
      "Step 27:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 28:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 463])\n",
      "\n",
      "Step 29:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 420])\n",
      "\n",
      "Step 30:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 418])\n",
      "\n",
      "Step 31:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 417])\n",
      "\n",
      "Step 32:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 463])\n",
      "\n",
      "Step 33:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 439])\n",
      "\n",
      "Step 34:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 430])\n",
      "\n",
      "Step 35:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 391])\n",
      "\n",
      "Step 36:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 452])\n",
      "\n",
      "Step 37:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 415])\n",
      "\n",
      "Step 38:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 490])\n",
      "\n",
      "Step 39:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 396])\n",
      "\n",
      "Step 40:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 459])\n",
      "\n",
      "Step 41:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 429])\n",
      "\n",
      "Step 42:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 407])\n",
      "\n",
      "Step 43:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 467])\n",
      "\n",
      "Step 44:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 486])\n",
      "\n",
      "Step 45:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 413])\n",
      "\n",
      "Step 46:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 421])\n",
      "\n",
      "Step 47:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 496])\n",
      "\n",
      "Step 48:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 417])\n",
      "\n",
      "Step 49:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 403])\n",
      "\n",
      "Step 50:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 402])\n",
      "\n",
      "Step 51:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 459])\n",
      "\n",
      "Step 52:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 432])\n",
      "\n",
      "Step 53:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 412])\n",
      "\n",
      "Step 54:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 426])\n",
      "\n",
      "Step 55:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 508])\n",
      "\n",
      "Step 56:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 420])\n",
      "\n",
      "Step 57:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 375])\n",
      "\n",
      "Step 58:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 479])\n",
      "\n",
      "Step 59:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 463])\n",
      "\n",
      "Step 60:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 363])\n",
      "\n",
      "Step 61:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 408])\n",
      "\n",
      "Step 62:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 476])\n",
      "\n",
      "Step 63:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 403])\n",
      "\n",
      "Step 64:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 477])\n",
      "\n",
      "Step 65:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 66:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 407])\n",
      "\n",
      "Step 67:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 432])\n",
      "\n",
      "Step 68:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 424])\n",
      "\n",
      "Step 69:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 459])\n",
      "\n",
      "Step 70:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 420])\n",
      "\n",
      "Step 71:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 410])\n",
      "\n",
      "Step 72:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 473])\n",
      "\n",
      "Step 73:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 457])\n",
      "\n",
      "Step 74:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 379])\n",
      "\n",
      "Step 75:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 487])\n",
      "\n",
      "Step 76:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 424])\n",
      "\n",
      "Step 77:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 410])\n",
      "\n",
      "Step 78:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 461])\n",
      "\n",
      "Step 79:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 80:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 398])\n",
      "\n",
      "Step 81:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 412])\n",
      "\n",
      "Step 82:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 426])\n",
      "\n",
      "Step 83:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 430])\n",
      "\n",
      "Step 84:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 420])\n",
      "\n",
      "Step 85:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 481])\n",
      "\n",
      "Step 86:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 389])\n",
      "\n",
      "Step 87:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 466])\n",
      "\n",
      "Step 88:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 372])\n",
      "\n",
      "Step 89:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 387])\n",
      "\n",
      "Step 90:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 484])\n",
      "\n",
      "Step 91:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 420])\n",
      "\n",
      "Step 92:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 483])\n",
      "\n",
      "Step 93:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 739])\n",
      "\n",
      "Step 94:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 603])\n",
      "\n",
      "Step 95:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 482])\n",
      "\n",
      "Step 96:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 419])\n",
      "\n",
      "Step 97:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 469])\n",
      "\n",
      "Step 98:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 418])\n",
      "\n",
      "Step 99:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 484])\n",
      "\n",
      "Step 100:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 499])\n",
      "\n",
      "Step 101:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 483])\n",
      "\n",
      "Step 102:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 461])\n",
      "\n",
      "Step 103:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 417])\n",
      "\n",
      "Step 104:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 468])\n",
      "\n",
      "Step 105:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 492])\n",
      "\n",
      "Step 106:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 442])\n",
      "\n",
      "Step 107:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 108:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 442])\n",
      "\n",
      "Step 109:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 423])\n",
      "\n",
      "Step 110:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 464])\n",
      "\n",
      "Step 111:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 475])\n",
      "\n",
      "Step 112:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 381])\n",
      "\n",
      "Step 113:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 431])\n",
      "\n",
      "Step 114:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 496])\n",
      "\n",
      "Step 115:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 457])\n",
      "\n",
      "Step 116:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 434])\n",
      "\n",
      "Step 117:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 118:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 540])\n",
      "\n",
      "Step 119:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 492])\n",
      "\n",
      "Step 120:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 414])\n",
      "\n",
      "Step 121:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 457])\n",
      "\n",
      "Step 122:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 394])\n",
      "\n",
      "Step 123:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 413])\n",
      "\n",
      "Step 124:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 460])\n",
      "\n",
      "Step 125:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 126:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 442])\n",
      "\n",
      "Step 127:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 537])\n",
      "\n",
      "Step 128:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 498])\n",
      "\n",
      "Step 129:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 474])\n",
      "\n",
      "Step 130:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 456])\n",
      "\n",
      "Step 131:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 469])\n",
      "\n",
      "Step 132:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 433])\n",
      "\n",
      "Step 133:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 403])\n",
      "\n",
      "Step 134:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 480])\n",
      "\n",
      "Step 135:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 460])\n",
      "\n",
      "Step 136:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 600])\n",
      "\n",
      "Step 137:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 417])\n",
      "\n",
      "Step 138:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 412])\n",
      "\n",
      "Step 139:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 465])\n",
      "\n",
      "Step 140:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 470])\n",
      "\n",
      "Step 141:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 392])\n",
      "\n",
      "Step 142:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 475])\n",
      "\n",
      "Step 143:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 556])\n",
      "\n",
      "Step 144:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 430])\n",
      "\n",
      "Step 145:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 470])\n",
      "\n",
      "Step 146:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 147:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 414])\n",
      "\n",
      "Step 148:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 422])\n",
      "\n",
      "Step 149:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 414])\n",
      "\n",
      "Step 150:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 151:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 543])\n",
      "\n",
      "Step 152:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 556])\n",
      "\n",
      "Step 153:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 486])\n",
      "\n",
      "Step 154:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 435])\n",
      "\n",
      "Step 155:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 401])\n",
      "\n",
      "Step 156:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 476])\n",
      "\n",
      "Step 157:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 473])\n",
      "\n",
      "Step 158:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 472])\n",
      "\n",
      "Step 159:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 437])\n",
      "\n",
      "Step 160:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 443])\n",
      "\n",
      "Step 161:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 442])\n",
      "\n",
      "Step 162:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 396])\n",
      "\n",
      "Step 163:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 422])\n",
      "\n",
      "Step 164:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 400])\n",
      "\n",
      "Step 165:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 529])\n",
      "\n",
      "Step 166:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 440])\n",
      "\n",
      "Step 167:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 479])\n",
      "\n",
      "Step 168:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 492])\n",
      "\n",
      "Step 169:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 640])\n",
      "\n",
      "Step 170:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 453])\n",
      "\n",
      "Step 171:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 446])\n",
      "\n",
      "Step 172:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 460])\n",
      "\n",
      "Step 173:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 441])\n",
      "\n",
      "Step 174:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 398])\n",
      "\n",
      "Step 175:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 664])\n",
      "\n",
      "Step 176:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 501])\n",
      "\n",
      "Step 177:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 440])\n",
      "\n",
      "Step 178:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 419])\n",
      "\n",
      "Step 179:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 412])\n",
      "\n",
      "Step 180:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 455])\n",
      "\n",
      "Step 181:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 557])\n",
      "\n",
      "Step 182:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 434])\n",
      "\n",
      "Step 183:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 435])\n",
      "\n",
      "Step 184:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 407])\n",
      "\n",
      "Step 185:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 467])\n",
      "\n",
      "Step 186:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 484])\n",
      "\n",
      "Step 187:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 412])\n",
      "\n",
      "Step 188:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 469])\n",
      "\n",
      "Step 189:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 427])\n",
      "\n",
      "Step 190:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 453])\n",
      "\n",
      "Step 191:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 452])\n",
      "\n",
      "Step 192:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 408])\n",
      "\n",
      "Step 193:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 432])\n",
      "\n",
      "Step 194:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 393])\n",
      "\n",
      "Step 195:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 467])\n",
      "\n",
      "Step 196:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 446])\n",
      "\n",
      "Step 197:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 452])\n",
      "\n",
      "Step 198:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 456])\n",
      "\n",
      "Step 199:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 545])\n",
      "\n",
      "Step 200:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 494])\n",
      "\n",
      "Step 201:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 451])\n",
      "\n",
      "Step 202:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 479])\n",
      "\n",
      "Step 203:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 445])\n",
      "\n",
      "Step 204:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 434])\n",
      "\n",
      "Step 205:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 492])\n",
      "\n",
      "Step 206:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 446])\n",
      "\n",
      "Step 207:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 471])\n",
      "\n",
      "Step 208:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 508])\n",
      "\n",
      "Step 209:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 493])\n",
      "\n",
      "Step 210:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 392])\n",
      "\n",
      "Step 211:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 394])\n",
      "\n",
      "Step 212:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 455])\n",
      "\n",
      "Step 213:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 423])\n",
      "\n",
      "Step 214:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 450])\n",
      "\n",
      "Step 215:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 442])\n",
      "\n",
      "Step 216:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 409])\n",
      "\n",
      "Step 217:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 425])\n",
      "\n",
      "Step 218:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 404])\n",
      "\n",
      "Step 219:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 422])\n",
      "\n",
      "Step 220:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 397])\n",
      "\n",
      "Step 221:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 492])\n",
      "\n",
      "Step 222:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 490])\n",
      "\n",
      "Step 223:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 391])\n",
      "\n",
      "Step 224:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 390])\n",
      "\n",
      "Step 225:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 382])\n",
      "\n",
      "Step 226:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 392])\n",
      "\n",
      "Step 227:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 539])\n",
      "\n",
      "Step 228:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 395])\n",
      "\n",
      "Step 229:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 362])\n",
      "\n",
      "Step 230:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 382])\n",
      "\n",
      "Step 231:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 497])\n",
      "\n",
      "Step 232:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 416])\n",
      "\n",
      "Step 233:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 470])\n",
      "\n",
      "Step 234:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 235:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 236:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 471])\n",
      "\n",
      "Step 237:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 373])\n",
      "\n",
      "Step 238:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 425])\n",
      "\n",
      "Step 239:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 371])\n",
      "\n",
      "Step 240:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 446])\n",
      "\n",
      "Step 241:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 431])\n",
      "\n",
      "Step 242:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 388])\n",
      "\n",
      "Step 243:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 448])\n",
      "\n",
      "Step 244:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 393])\n",
      "\n",
      "Step 245:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 487])\n",
      "\n",
      "Step 246:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 451])\n",
      "\n",
      "Step 247:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 410])\n",
      "\n",
      "Step 248:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 461])\n",
      "\n",
      "Step 249:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 455])\n",
      "\n",
      "Step 250:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 416])\n",
      "\n",
      "Step 251:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 425])\n",
      "\n",
      "Step 252:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 446])\n",
      "\n",
      "Step 253:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 430])\n",
      "\n",
      "Step 254:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 434])\n",
      "\n",
      "Step 255:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 428])\n",
      "\n",
      "Step 256:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 407])\n",
      "\n",
      "Step 257:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 408])\n",
      "\n",
      "Step 258:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 416])\n",
      "\n",
      "Step 259:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 433])\n",
      "\n",
      "Step 260:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 448])\n",
      "\n",
      "Step 261:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 454])\n",
      "\n",
      "Step 262:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 417])\n",
      "\n",
      "Step 263:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 480])\n",
      "\n",
      "Step 264:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 411])\n",
      "\n",
      "Step 265:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 504])\n",
      "\n",
      "Step 266:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 468])\n",
      "\n",
      "Step 267:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 491])\n",
      "\n",
      "Step 268:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 427])\n",
      "\n",
      "Step 269:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 526])\n",
      "\n",
      "Step 270:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 492])\n",
      "\n",
      "Step 271:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 446])\n",
      "\n",
      "Step 272:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 396])\n",
      "\n",
      "Step 273:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 484])\n",
      "\n",
      "Step 274:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 442])\n",
      "\n",
      "Step 275:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 414])\n",
      "\n",
      "Step 276:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 455])\n",
      "\n",
      "Step 277:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 455])\n",
      "\n",
      "Step 278:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 435])\n",
      "\n",
      "Step 279:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 401])\n",
      "\n",
      "Step 280:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 399])\n",
      "\n",
      "Step 281:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 437])\n",
      "\n",
      "Step 282:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 409])\n",
      "\n",
      "Step 283:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 444])\n",
      "\n",
      "Step 284:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 389])\n",
      "\n",
      "Step 285:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 455])\n",
      "\n",
      "Step 286:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 384])\n",
      "\n",
      "Step 287:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 505])\n",
      "\n",
      "Step 288:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 421])\n",
      "\n",
      "Step 289:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 465])\n",
      "\n",
      "Step 290:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 452])\n",
      "\n",
      "Step 291:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 480])\n",
      "\n",
      "Step 292:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 416])\n",
      "\n",
      "Step 293:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 416])\n",
      "\n",
      "Step 294:\n",
      "=======\n",
      "Number of graphs in the current batch: 128\n",
      "torch.Size([2, 595])\n",
      "\n",
      "Step 295:\n",
      "=======\n",
      "Number of graphs in the current batch: 10\n",
      "torch.Size([2, 33])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training a Graph Neural Network (GNN)\n",
    "\n",
    "Training a GNN for graph classification usually follows a simple recipe:\n",
    "\n",
    "1. Embed each node by performing multiple rounds of message passing\n",
    "2. Aggregate node embeddings into a unified graph embedding (**readout layer**)\n",
    "3. Train a final classifier on the graph embedding\n",
    "\n",
    "There exists multiple **readout layers** in literature, but the most common one is to simply take the average of node embeddings:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{\\mathcal{G}} = \\frac{1}{|\\mathcal{V}|} \\sum_{v \\in \\mathcal{V}} \\mathcal{x}^{(L)}_v\n",
    "$$\n",
    "\n",
    "PyTorch Geometric provides this functionality via [`torch_geometric.nn.global_mean_pool`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.glob.global_mean_pool), which takes in the node embeddings of all nodes in the mini-batch and the assignment vector `batch` to compute a graph embedding of size `[batch_size, hidden_channels]` for each graph in the batch.\n",
    "\n",
    "The final architecture for applying GNNs to the task of graph classification then looks as follows and allows for complete end-to-end training:"
   ],
   "id": "11cd8122b148ed2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:38:10.909048Z",
     "start_time": "2025-05-07T13:38:10.906892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_node_features = 1\n",
    "dim_global_features = 0\n",
    "hidden_channels = 256  # adjust as needed\n",
    "num_classes = 2  # binary classification"
   ],
   "id": "815f18340eede44b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:38:11.195708Z",
     "start_time": "2025-05-07T13:38:11.184703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_GNNSAGE = gnn.GraphSAGE(\n",
    "    num_node_features + dim_global_features, hidden_channels, num_classes\n",
    ")\n",
    "print(model_GNNSAGE)"
   ],
   "id": "ece911903caf5ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (conv1): SAGEConv(1, 256, aggr=mean)\n",
      "  (conv2): SAGEConv(256, 256, aggr=mean)\n",
      "  (conv3): SAGEConv(256, 256, aggr=mean)\n",
      "  (conv4): SAGEConv(256, 256, aggr=mean)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T13:40:53.463530Z",
     "start_time": "2025-05-07T13:40:53.457714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(model_GNNSAGE.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"mps\")\n",
    "model_GNNSAGE.to(device)"
   ],
   "id": "fdac29712ebdf98b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGE(\n",
       "  (conv1): SAGEConv(1, 256, aggr=mean)\n",
       "  (conv2): SAGEConv(256, 256, aggr=mean)\n",
       "  (conv3): SAGEConv(256, 256, aggr=mean)\n",
       "  (conv4): SAGEConv(256, 256, aggr=mean)\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T14:04:24.632428Z",
     "start_time": "2025-05-07T13:40:54.726348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gnn.run_experiment(\n",
    "    \"Graph SAGE\", 20, model_GNNSAGE, train_loader, test_loader, optimizer, criterion, device\n",
    ")"
   ],
   "id": "420e705008846cf3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 15:40:54 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.5.1, but the installed version is 2.6.0. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:35<11:08, 35.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.1536, Test Acc: 0.9595\n",
      "Epoch 2 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [01:15<11:32, 38.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.1531, Test Acc: 0.9606\n",
      "Epoch 3 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3/20 [02:06<12:28, 44.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.1524, Test Acc: 0.9614\n",
      "Epoch 4 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [03:00<12:44, 47.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.1521, Test Acc: 0.9611\n",
      "Epoch 5 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [03:51<12:17, 49.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.1520, Test Acc: 0.9613\n",
      "Epoch 6 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [04:47<11:58, 51.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.1520, Test Acc: 0.9610\n",
      "Epoch 7 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [05:45<11:37, 53.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 0.1519, Test Acc: 0.9614\n",
      "Epoch 8 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [06:44<11:02, 55.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 0.1516, Test Acc: 0.9609\n",
      "Epoch 9 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [07:46<10:30, 57.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.1515, Test Acc: 0.9614\n",
      "Epoch 10 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [08:47<09:45, 58.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.1516, Test Acc: 0.9612\n",
      "Epoch 11 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [09:56<09:15, 61.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 0.1511, Test Acc: 0.9610\n",
      "Epoch 12 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [11:02<08:24, 63.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.1514, Test Acc: 0.9609\n",
      "Epoch 13 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [12:07<07:25, 63.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 0.1508, Test Acc: 0.9611\n",
      "Epoch 14 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [13:31<06:58, 69.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 0.1507, Test Acc: 0.9612\n",
      "Epoch 15 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [15:01<06:19, 75.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 0.1511, Test Acc: 0.9611\n",
      "Epoch 16 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [16:26<05:14, 78.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 0.1507, Test Acc: 0.9612\n",
      "Epoch 17 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [17:57<04:07, 82.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 0.1509, Test Acc: 0.9612\n",
      "Epoch 18 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [20:05<03:12, 96.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 0.1506, Test Acc: 0.9612\n",
      "Epoch 19 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [21:46<01:37, 97.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 0.1502, Test Acc: 0.9615\n",
      "Epoch 20 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [23:23<00:00, 70.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: 0.1503, Test Acc: 0.9613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[31m2025/05/07 16:04:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run unique-lynx-535 at: http://127.0.0.1:8080/#/experiments/145054897104438872/runs/248d98ce560c44f2a563e94804dd14b3\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/145054897104438872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GraphSAGE(\n",
       "   (conv1): SAGEConv(1, 256, aggr=mean)\n",
       "   (conv2): SAGEConv(256, 256, aggr=mean)\n",
       "   (conv3): SAGEConv(256, 256, aggr=mean)\n",
       "   (conv4): SAGEConv(256, 256, aggr=mean)\n",
       "   (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       " ),\n",
       " {})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:31:53.036611Z",
     "start_time": "2025-05-08T14:31:52.796176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_uri = \"mlflow-artifacts:/145054897104438872/248d98ce560c44f2a563e94804dd14b3/artifacts/model\"\n",
    "model_GNNSAGE = mlflow.pytorch.load_model(model_uri)"
   ],
   "id": "6af868858eb3effc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9db100b2e344ab28345e36b00a2dcc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:32:03.579638Z",
     "start_time": "2025-05-08T14:31:53.045367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_GNNSAGE.eval()\n",
    "device = torch.device(\"mps\")\n",
    "model_GNNSAGE.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model_GNNSAGE(data)\n",
    "        preds = out.argmax(dim=1).cpu().numpy()\n",
    "        labels = data.y.cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "#         for data in loader:\n",
    "#             # data.x = torch.cat([data.x, data.global_features[data.batch].unsqueeze(1)], dim=-1)\n",
    "#             data = data.to(device)\n",
    "#             if return_embeddings:\n",
    "#                 out, emb = model(data, return_embeddings)\n",
    "#                 mapping = {trx_id: emb for trx_id, emb in zip(data.trx_id, emb)}\n",
    "#                 embeddings.update(mapping)\n",
    "#             else:\n",
    "#                 out = model(data)\n",
    "#             loss = criterion(out, data.y)\n",
    "#             total_loss += loss.item() * data.num_graphs\n",
    "#             pred = out.argmax(dim=1)\n",
    "#             correct += (pred == data.y).sum().item()\n",
    "#             total += data.num_graphs\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ],
   "id": "f52f0214d8394140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9612666702088093\n",
      "Precision: 0.9621165063875922\n",
      "Recall: 0.9612666702088093\n",
      "F1 Score: 0.9610217489492596\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T16:19:19.551135Z",
     "start_time": "2025-03-13T16:19:15.769625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        if data.num_graphs != len(data.trx_id):\n",
    "            print(\"Batch num_graphs:\", data.num_graphs)\n",
    "            print(\"Number of trx_ids:\", len(data.trx_id))"
   ],
   "id": "4cb940d8341127c5",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:45:54.726059Z",
     "start_time": "2025-03-13T13:45:16.606460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss, acc, embeddings = gnn.test(\n",
    "    model_GNNSAGE, data_loader, criterion, device, return_embeddings=True\n",
    ")"
   ],
   "id": "6ef6f83a5951069",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:46:23.167224Z",
     "start_time": "2025-03-13T13:46:23.159337Z"
    }
   },
   "cell_type": "code",
   "source": "len(embeddings)",
   "id": "7292b470d64bf8b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:46:49.252820Z",
     "start_time": "2025-03-13T13:46:26.697586Z"
    }
   },
   "cell_type": "code",
   "source": "emb = {trx_id: emb.cpu().detach().numpy() for trx_id, emb in embeddings.items()}",
   "id": "5e77a7d0adb46712",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:46:49.293160Z",
     "start_time": "2025-03-13T13:46:49.265338Z"
    }
   },
   "cell_type": "code",
   "source": "pd_embeddings = pd.DataFrame({\"transactionHash\": emb.keys(), \"embeddings\": emb.values()})",
   "id": "518277eb1e8ab86c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:47:32.248782Z",
     "start_time": "2025-03-13T13:46:49.481646Z"
    }
   },
   "cell_type": "code",
   "source": "pd_embeddings.to_csv(config.FLASHBOTS_Q2_DATA_DIR / \"embeddings_128.csv\", index=False)",
   "id": "906249c6e7540d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:34:51.821614Z",
     "start_time": "2025-03-12T15:34:51.818733Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_channels, num_classes, edge_attr_dim):\n",
    "        super(GAT, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GATv2Conv(input_features, hidden_channels, edge_dim=edge_attr_dim)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels, edge_dim=edge_attr_dim)\n",
    "        self.conv3 = GATv2Conv(hidden_channels, hidden_channels, edge_dim=edge_attr_dim)\n",
    "        self.conv4 = GATv2Conv(hidden_channels, hidden_channels, edge_dim=edge_attr_dim)\n",
    "        self.lin = Linear(hidden_channels, 256)\n",
    "        self.lin2 = Linear(256, num_classes)\n",
    "        self.batchnorm = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(data.x, data.edge_index, data.edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, data.edge_index, data.edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, data.edge_index, data.edge_attr)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, data.batch, size=data.num_graphs)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # x = self.batchnorm(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ],
   "id": "510ea6b2b961a137"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:41:44.748430Z",
     "start_time": "2025-03-12T15:36:37.774900Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 1/9 [03:31<28:08, 211.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.6717, Test Acc: 0.6042\n",
      "Epoch 2 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 1/9 [05:06<40:53, 306.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m10\u001B[39m)):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m starts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_GAT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     loss, acc, embeddings \u001B[38;5;241m=\u001B[39m test(model_GAT, test_loader, criterion, device)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[8], line 7\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, loader, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# data.x = torch.cat([data.x, data.global_features[data.batch].unsqueeze(1)], dim=-1)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 7\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(out, data\u001B[38;5;241m.\u001B[39my)\n\u001B[1;32m      9\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[4], line 15\u001B[0m, in \u001B[0;36mGAT.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;66;03m# 1. Obtain node embeddings\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[1;32m     17\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x, data\u001B[38;5;241m.\u001B[39medge_index, data\u001B[38;5;241m.\u001B[39medge_attr)\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/conv/gatv2_conv.py:325\u001B[0m, in \u001B[0;36mGATv2Conv.forward\u001B[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001B[0m\n\u001B[1;32m    319\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    320\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe usage of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_attr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd_self_loops\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimultaneously is currently not yet supported for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseTensor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m form\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    324\u001B[0m \u001B[38;5;66;03m# edge_updater_type: (x: PairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[0;32m--> 325\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_updater\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m                          \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: PairTensor, alpha: Tensor)\u001B[39;00m\n\u001B[1;32m    329\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(edge_index, x\u001B[38;5;241m=\u001B[39m(x_l, x_r), alpha\u001B[38;5;241m=\u001B[39malpha)\n",
      "File \u001B[0;32m/var/folders/zd/5rj11nhj5h98j5kmp_lp5k5w0000gn/T/torch_geometric.nn.conv.gatv2_conv_GATv2Conv_edge_updater_koae_tan.py:176\u001B[0m, in \u001B[0;36medge_updater\u001B[0;34m(self, edge_index, x, edge_attr, size)\u001B[0m\n\u001B[1;32m    166\u001B[0m             kwargs \u001B[38;5;241m=\u001B[39m CollectArgs(\n\u001B[1;32m    167\u001B[0m                 x_j\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_j\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    168\u001B[0m                 x_i\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_i\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    172\u001B[0m                 dim_size\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    173\u001B[0m             )\n\u001B[1;32m    174\u001B[0m \u001B[38;5;66;03m# End Edge Update Forward Pre Hook #########################################\u001B[39;00m\n\u001B[0;32m--> 176\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_update\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_j\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_j\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_i\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Begin Edge Update Forward Hook ###########################################\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling():\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/conv/gatv2_conv.py:370\u001B[0m, in \u001B[0;36mGATv2Conv.edge_update\u001B[0;34m(self, x_j, x_i, edge_attr, index, ptr, dim_size)\u001B[0m\n\u001B[1;32m    368\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mleaky_relu(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnegative_slope)\n\u001B[1;32m    369\u001B[0m alpha \u001B[38;5;241m=\u001B[39m (x \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39matt)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 370\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    371\u001B[0m alpha \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(alpha, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m alpha\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/utils/_softmax.py:78\u001B[0m, in \u001B[0;36msoftmax\u001B[0;34m(src, index, ptr, num_nodes, dim)\u001B[0m\n\u001B[1;32m     76\u001B[0m     out \u001B[38;5;241m=\u001B[39m src \u001B[38;5;241m-\u001B[39m src_max\u001B[38;5;241m.\u001B[39mindex_select(dim, index)\n\u001B[1;32m     77\u001B[0m     out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mexp()\n\u001B[0;32m---> 78\u001B[0m     out_sum \u001B[38;5;241m=\u001B[39m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-16\u001B[39m\n\u001B[1;32m     79\u001B[0m     out_sum \u001B[38;5;241m=\u001B[39m out_sum\u001B[38;5;241m.\u001B[39mindex_select(dim, index)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/utils/_scatter.py:75\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     74\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_zeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     78\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "edge_attr_dim = 2\n",
    "model_GAT = GAT(num_node_features, hidden_channels, num_classes, edge_attr_dim)\n",
    "optimizer = torch.optim.Adam(model_GAT.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"mps\")\n",
    "model_GAT.to(device)\n",
    "\n",
    "for epoch in tqdm(range(1, 10)):\n",
    "    print(f\"Epoch {epoch} starts\")\n",
    "    loss = train(model_GAT, train_loader, optimizer, criterion, device)\n",
    "    loss, acc, embeddings = test(model_GAT, test_loader, criterion, device)\n",
    "    print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Test Acc: {acc:.4f}\")"
   ],
   "id": "9c1ca42614a30732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:46:21.832106Z",
     "start_time": "2025-03-12T15:46:21.826515Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 21,
   "source": [
    "class GINE(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_channels, num_classes, edge_attr_dim):\n",
    "        super(GINE, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        mlp1 = nn.Sequential(\n",
    "            nn.Linear(input_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.conv1 = GINEConv(mlp1, edge_dim=edge_attr_dim)\n",
    "\n",
    "        mlp2 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.conv2 = GINEConv(mlp2, edge_dim=edge_attr_dim)\n",
    "\n",
    "        mlp3 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.conv3 = GINEConv(mlp3, edge_dim=edge_attr_dim)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, 256)\n",
    "        self.lin2 = Linear(256, num_classes)\n",
    "        self.batchnorm = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 1. Obtain node embeddings\n",
    "        # edge_attr = data.edge_attr.unsqueeze(-1)  # Now shape: [num_edges, 1]\n",
    "\n",
    "        x = self.conv1(data.x, data.edge_index, data.edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, data.edge_index, data.edge_attr)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, data.edge_index, data.edge_attr)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, data.batch, size=data.num_graphs)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # x = self.batchnorm(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ],
   "id": "c7f1c839c4d8e932"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:55:23.533758Z",
     "start_time": "2025-03-12T15:52:11.666347Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 1/9 [00:56<07:30, 56.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.5691, Test Acc: 0.7184\n",
      "Epoch 2 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 2/9 [03:05<11:34, 99.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.5684, Test Acc: 0.7184\n",
      "Epoch 3 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 2/9 [03:11<11:11, 95.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m10\u001B[39m)):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m starts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_GINE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     loss, acc, embeddings \u001B[38;5;241m=\u001B[39m test(model_GINE, test_loader, criterion, device)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[8], line 7\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, loader, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# data.x = torch.cat([data.x, data.global_features[data.batch].unsqueeze(1)], dim=-1)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 7\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(out, data\u001B[38;5;241m.\u001B[39my)\n\u001B[1;32m      9\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[21], line 41\u001B[0m, in \u001B[0;36mGINE.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     38\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(x, data\u001B[38;5;241m.\u001B[39medge_index, data\u001B[38;5;241m.\u001B[39medge_attr)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# 2. Readout layer\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mglobal_mean_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_graphs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# 3. Apply a final classifier\u001B[39;00m\n\u001B[1;32m     44\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin(x)\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/pool/glob.py:63\u001B[0m, in \u001B[0;36mglobal_mean_pool\u001B[0;34m(x, batch, size)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39mdim, keepdim\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/utils/_scatter.py:79\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     78\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n\u001B[0;32m---> 79\u001B[0m     count\u001B[38;5;241m.\u001B[39mscatter_add_(\u001B[38;5;241m0\u001B[39m, index, \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_ones\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     80\u001B[0m     count \u001B[38;5;241m=\u001B[39m count\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     82\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 23,
   "source": [
    "edge_attr_dim = 2\n",
    "model_GINE = GINE(num_node_features, hidden_channels, num_classes, edge_attr_dim)\n",
    "optimizer = torch.optim.Adam(model_GINE.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"mps\")\n",
    "model_GINE.to(device)\n",
    "\n",
    "for epoch in tqdm(range(1, 10)):\n",
    "    print(f\"Epoch {epoch} starts\")\n",
    "    loss = train(model_GINE, train_loader, optimizer, criterion, device)\n",
    "    loss, acc, embeddings = test(model_GINE, test_loader, criterion, device)\n",
    "    print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Test Acc: {acc:.4f}\")"
   ],
   "id": "21046fcfd95853c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:43:48.550533Z",
     "start_time": "2025-03-12T15:43:48.547108Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 18,
   "source": [
    "class GINC(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_channels, num_classes):\n",
    "        super(GINC, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        mlp1 = nn.Sequential(\n",
    "            nn.Linear(input_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.conv1 = GINConv(mlp1)\n",
    "\n",
    "        mlp2 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.conv2 = GINConv(mlp2)\n",
    "\n",
    "        mlp3 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.conv3 = GINConv(mlp3)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, 256)\n",
    "        self.lin2 = Linear(256, num_classes)\n",
    "        self.batchnorm = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(data.x, data.edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, data.edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, data.edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, data.batch, size=data.num_graphs)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # x = self.batchnorm(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ],
   "id": "b2577dbe9a7b41ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:05:42.413304Z",
     "start_time": "2025-03-12T15:05:03.830082Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:16<02:31, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 0.2053, Test Acc: 0.9325\n",
      "Epoch 1 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [00:32<02:07, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.2182, Test Acc: 0.9325\n",
      "Epoch 2 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [00:38<02:33, 19.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m10\u001B[39m)):\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m starts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_GINC\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     loss, acc, embeddings \u001B[38;5;241m=\u001B[39m test(model_GINC, test_loader, criterion, device)\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[15], line 7\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, loader, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# data.x = torch.cat([data.x, data.global_features[data.batch].unsqueeze(1)], dim=-1)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 7\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(out, data\u001B[38;5;241m.\u001B[39my)\n\u001B[1;32m      9\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[60], line 34\u001B[0m, in \u001B[0;36mGINC.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     32\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(data\u001B[38;5;241m.\u001B[39mx, data\u001B[38;5;241m.\u001B[39medge_index)\n\u001B[1;32m     33\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[0;32m---> 34\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[1;32m     36\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(x, data\u001B[38;5;241m.\u001B[39medge_index)\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/conv/gin_conv.py:84\u001B[0m, in \u001B[0;36mGINConv.forward\u001B[0;34m(self, x, edge_index, size)\u001B[0m\n\u001B[1;32m     81\u001B[0m     x \u001B[38;5;241m=\u001B[39m (x, x)\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m x_r \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x_r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/var/folders/zd/5rj11nhj5h98j5kmp_lp5k5w0000gn/T/torch_geometric.nn.conv.gin_conv_GINConv_propagate_vhxtzj0f.py:229\u001B[0m, in \u001B[0;36mpropagate\u001B[0;34m(self, edge_index, x, size)\u001B[0m\n\u001B[1;32m    221\u001B[0m             kwargs \u001B[38;5;241m=\u001B[39m CollectArgs(\n\u001B[1;32m    222\u001B[0m                 x_j\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mx_j,\n\u001B[1;32m    223\u001B[0m                 index\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    224\u001B[0m                 ptr\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mptr\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    225\u001B[0m                 dim_size\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    226\u001B[0m             )\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001B[39;00m\n\u001B[0;32m--> 229\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggregate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m    \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling():\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[0;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21maggregate\u001B[39m(\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    579\u001B[0m     inputs: Tensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    582\u001B[0m     dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    583\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    584\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[1;32m    586\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 594\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/experimental.py:117\u001B[0m, in \u001B[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_experimental_mode_enabled(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisable_dynamic_shapes\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m required_arg \u001B[38;5;129;01min\u001B[39;00m required_args:\n\u001B[1;32m    120\u001B[0m         index \u001B[38;5;241m=\u001B[39m required_args_pos[required_arg]\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/aggr/base.py:131\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m     dim_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mIndexError\u001B[39;00m, \u001B[38;5;167;01mRuntimeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/aggr/basic.py:22\u001B[0m, in \u001B[0;36mSumAggregation.forward\u001B[0;34m(self, x, index, ptr, dim_size, dim)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor, index: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     20\u001B[0m             ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     21\u001B[0m             dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/nn/aggr/base.py:185\u001B[0m, in \u001B[0;36mAggregation.reduce\u001B[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAggregation requires \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to be specified\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Uni/2_Master/4_FS25_Programming/graph-reinforcement-learning-using-blockchain-data/venv/lib/python3.12/site-packages/torch_geometric/utils/_scatter.py:75\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     74\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_zeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     78\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 63,
   "source": [
    "model_GINC = GINC(num_node_features, hidden_channels, num_classes)\n",
    "optimizer = torch.optim.Adam(model_GINC.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"mps\")\n",
    "model_GINC.to(device)\n",
    "\n",
    "for epoch in tqdm(range(0, 10)):\n",
    "    print(f\"Epoch {epoch} starts\")\n",
    "    loss = train(model_GINC, train_loader, optimizer, criterion, device)\n",
    "    loss, acc, embeddings = test(model_GINC, test_loader, criterion, device)\n",
    "    print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Test Acc: {acc:.4f}\")"
   ],
   "id": "609d272a35cb7d11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
